---
layout: post
title: （三）STL那些事儿：字符编码与std::string
categories: C++
related_posts: True
tags: STL
toc:
  sidebar: right
---

## （三）STL那些事儿：字符编码与std::string

### 1. concepts

- **计算机如何存储的？**

计算机存储数据的底层机制基于电信号的有无，以二进制的`0`和`1`来表示信息。多个`0`和`1`的组合可以表示不同的数值，无论是二进制、十六进制还是十进制，本质上都是对这些数值的不同表示形式。然而计算机要处理文字信息，而不是数值，所以就需要人为地建立起这些数值与字符之间的对应关系。

### 2. 字符集

- **字符集的概念**

为了让计算机能够表示文字，人们制定了不同的字符集。字符集就是规定了整数与字符之间映射关系的集合。例如，规定`61`代表字符`a`，`62`代表字符`b`等。常见的字符集有`ASCII`和`Unicode`。`ASCII`字符集主要用于支持英文文本，它的编码范围有限，无法表示中文等其他语言的字符。而`Unicode`字符集则致力于支持全球主流的所有文本，几乎涵盖了世界上所有的字符。Unicode 是一个国际标准，用于为世界上所有的字符、符号和表情符号分配一个唯一的数字。这个数字被称为字符的 Unicode 码点。Unicode 的目标是能够表示所有的写作系统，包括拉丁字母、希腊字母、阿拉伯字母、汉字、象形文字等。 Unicode 标准定义了一系列的字符集，每个字符集包含一组字符和它们对应的码点。

#### 2.1 ASCII

ASCII（美国信息交换标准代码）是一种广泛使用的字符编码标准。

- **控制字符**：ASCII 编码的前 32 个字符（编码值从 0 到 31）被设定为控制字符。这些字符并非用于显示可见的文本内容，而是主要用于控制设备的操作。例如，换行符（ASCII 值为 10，在编程中通常表示为`\n`）用于指示文本换行，回车符（ASCII 值为 13，通常表示为`\r`）常用于将光标移动到当前行的开头，在早期的电传打字机和终端设备中起到重要的控制作用。
- **可打印字符**：ASCII 编码从 32 到 126 的这 95 个字符是可打印字符，涵盖了英文大小写字母（`a - z`、`A - Z`）、数字（`0 - 9`）、标点符号（如`.,;?!`等）以及一些特殊字符（如`$%&`等）。这些字符构成了英文文本处理的基础，使得计算机能够准确地表示和处理英文书写系统中的各种元素。
- **编码空间拓展**：ASCII 标准最初仅定义了 0 到 127 的字符集，这些字符仅需占用 7 位存储空间。然而，在实际的计算机系统和编码实现中，为了方便存储和处理，通常会使用 8 位（即一个字节）来存储每个字符。这样一来，就多出了 128 到 255 这 128 个编码值的空间。不同的系统和编码标准会利用这个额外的空间来定义更多的字符。例如，在 ISO 8859 - 1（又称 Latin - 1）编码中，128 到 255 这个范围被用于存储西欧语言中的特殊字符，像`á`、`ñ`、`ô`等，以满足这些语言在计算机中的字符表示需求。需要明确的是，这 128 到 255 的范围并不属于 ASCII 标准本身，而是由其他后续的编码标准所定义，并且在不同的编码标准中，这个范围所代表的字符集可能各不相同。

#### 2.2 本地字符集

本地字符集是指在特定地区或语言环境中使用的字符编码标准。由于不同地区的语言和文字系统各不相同，因此各地可能会采用不同的字符集来满足其特定的文本处理需求。例如，在中国大陆，GB2312 和 GBK 是常用的本地字符集，用于表示简体中文字符；而在台湾地区，Big5 是一种常见的本地字符集，用于表示繁体中文字符。这些本地字符集通常会扩展 ASCII 字符集，以包含更多适用于特定语言的字符，从而确保计算机能够正确地处理和显示该地区的文本内容。

常见的本地字符集包括：
- GB2312：主要用于简体中文字符的编码，包含了常用的汉字和符号。
- GBK：是 GB2312 的扩展，支持更多的汉字和符号。
- Big5：主要用于繁体中文字符的编码，广泛应用于台湾地区。

GBK字符集是由中国国家标准化管理委员会（SAC）于1995年发布的，作为对GB2312字符集的扩展，以支持更多的汉字和符号。GBK的全称是“汉字内码扩展规范”，它在GB2312的基础上增加了对繁体字和其他少数民族文字的支持。

#### 2.3 Unicode

Unicode诞生于1991年，在此之前，全球没有能覆盖多语言的通用字符方案，而是“各区域用各的编码”，核心问题是 **“编码不兼容”**。如果一旦出现跨区域交流，就会出现乱码问题。Unicode 的目标是为每一个字符分配一个唯一的码点，从而实现全球范围内的字符编码统一。


- Unicode 是一个字符集（或字符语义规范），把“可辨认的字符”映射为唯一的整数编号，称为 code point（码位），写作 U+XXXX（例如 U+0041 表示 'A'）。Unicode 覆盖的码点范围是 U+0000 .. U+10FFFF。  
- Unicode 并不规定这些码点如何在内存或磁盘上按字节排列——这由编码（encoding）来决定（例如 UTF‑8/UTF‑16/UTF‑32）。

- Code point、code unit、grapheme 的区别（常被混淆）  
  - code point：Unicode 定义的整数编号（最基础的单位）。  
  - code unit：某种编码下的基本存储单元（UTF‑8 的 code unit 是 8-bit、UTF‑16 是 16‑bit、UTF‑32 是 32‑bit）。一个 code point 在某种编码下会被编码为 1 个或多个 code unit。  
  - grapheme cluster（用户感知字符）：用户看到的“一个字符”可能由多个 code point 组成（例如字母 + 组合重音符、旗帜 emoji 由若干区域符码点组成）。文本处理常需按 grapheme 而不是按 code point 切分。

- **什么是BOM(Byte Order Mark)？**
BOM（Byte Order Mark，字节顺序标记）是一个特殊的 Unicode 字符，码点为 U+FEFF。它用于指示文本文件或数据流中多字节编码的字节顺序（大端序或小端序）。BOM 通常出现在文件的开头，帮助解析器正确地解释后续的字节数据。

BOM 是 Unicode 中的一个特殊字符，表示“零宽无断行空格”（Zero Width No-Break Space）。在文本文件中，BOM 的主要作用是指示文件使用的编码格式以及字节顺序。不同的编码格式有不同的 BOM 表示方式：
```
UTF‑8 BOM: EF BB BF
UTF‑16 LE: FF FE
UTF‑16 BE: FE FF
UTF‑32 LE: FF FE 00 00
UTF‑32 BE: 00 00 FE FF
```

简单来说，BOM是文件开头的一个特殊标记，告诉程序这个文件是用什么编码方式写的，从而确保正确地读取和显示文本内容。但是，并不是所有的文本文件都包含BOM，尤其是在UTF-8编码中，BOM是可选的。因为UTF-8的字节顺序是固定的，不存在大端或小端的问题。

### 3. 字符编码

字符集仅仅定义了字符与整数的映射，但是如果考虑到字符的实际存储和表示，还有这些等等问题需要考虑，比如多少字节表示这个整数，需不需要在头部和尾部用什么间隔开字符等等问题。简单说`Unicode`是字符集，规定整数和字符的映射关系；`UTF-8/16/32`是编码方式，规定若干个字节如何表示一个整数，这个整数根据`Unicode`表，才能映射得到字符。

- **为什么需要考虑用多少个字节表示一个整数呢？**

是因为不同字符在文本中出现的频率差异很大。如果所有字符出现频率相同，那每个字符都使用同样足够大的字节去表示一个整数好了，比如说四个字节表示一个整数，或者说表示一个字符。每个字符消耗相同的空间，便于处理。但在实际应用中，数字和英文字符的出现频率远高于中文、阿拉伯文等字符。

为了节省存储空间，会考虑采用变长编码，让常用字符占用较少的存储空间，不常用字符占用较多空间，从而在整体上优化存储空间的使用。比如说常用字符用两个字节，不常用字符用四个字节，每个字节的低几位作为一个字符的结束等等编码方式。

- **字符编码还需要考虑什么设计？**

  - 误码处理:在字符编码设计中，误码是一个重要的考量因素。当数据在存储或传输过程中，可能会出现单个比特（bit）的错误。一个好的编码设计应该尽量减少单个比特错误对其他数据的影响，确保即使出现误码，也不会破坏其他正常字符的数据完整性。例如，某些编码方式通过特定的校验机制或冗余信息，使得在检测到误码时能够进行一定程度的纠正或至少不影响后续字符的解析。

  - 定义域与空间利用:编码的定义域决定了它能够表示的字符范围。一般来说，定义域越大，能够表示的字符种类就越多，但同时也意味着可能需要更多的存储空间来表示每个字符。例如，`UTF - 32`能够直接表示非常广泛的字符范围，但每个字符固定占用 4 字节，相比其他编码方式在存储空间上较为浪费。在设计编码时，需要在满足应用所需字符集的前提下，平衡定义域大小和空间利用效率。

  - 开头结尾标记（变长编码）:对于变长编码，如何准确判断一个字符由几个字节组成是一个关键问题。通常的做法是在编码中添加开头结尾标记符，或者通过特定的编码规则来标识字符的边界。例如，`UTF - 8`通过字节的最高位模式来判断一个字符占用的字节数，从而实现准确的字符解析。这些标记或规则确保了在处理变长编码时，能够正确地识别每个字符的起始和结束位置，避免解析错误。

字符编码的设计是一个复杂的过程，需要综合考虑多种因素，以满足不同应用场景对字符表示、存储和处理的需求。上述只是其中一些重要的考量点，实际的编码设计还涉及到许多其他方面的细节和权衡。

- **Unicode 码点示例**
字母 A：U+0041（Unicode标准）
UTF‑8: `0x41`
UTF‑16: `0x00 0x41`
UTF‑32: `0x00 0x00 0x00 0x41`

#### 3.1 ANSI 与本地编码

在`Unicode`标准出现之前（Unicode也在在1991年才出现，推广普及更是走了很长一段时间），计算机系统主要依赖于各种本地编码来表示字符，这些本地编码通常是基于`ASCII`的扩展，用于支持特定语言和地区的字符集。在 Windows 操作系统中，这些本地编码被统称为`ANSI`编码。在 Windows 操作系统中，ANSI 编码通常指的是系统的本地代码页（code page），它是一种单字节或多字节的字符编码方式，用于表示特定语言环境下的字符集。不同的地区和语言环境会有不同的 ANSI 代码页，例如：
- **Code Page 1252**：用于西欧语言，如英语、法语、德语等。
- **Code Page 936**：用于简体中文（GBK 编码）。
- **Code Page 950**：用于繁体中文（Big5 编码）。

简单来说，首先是有了 ASCII 编码，但是非英语地区有使用当地语言需求，于是不同的地区和语言环境下，基于ASCII编码定义了各自的字符集。为了支持这些不同的字符集，windows操作系统推出一个ANSI（即windows本地编码）的概念。首先是windows自身有一个系统语言设置，这个系统语言设置决定了ANSI代码页，当程序输入一个字符串的时候，就会按照`ANSI`代码页对应的字符集去译码，得到真实文本。

当windows系统处理文本文件时，如果文件使用的是ANSI编码，系统会根据当前的本地代码页来解释这些字节，从而将其转换为对应的字符。这意味着同一个ANSI编码的文件，在不同的系统环境下可能会被解释为不同的字符，导致显示错误或乱码。

##### 3.1.1 windows下的ANSI 开发

而现在windows内核/文件系统、注册表等底层接口，大多数仍然支持ANSI编码的API，比如说`CreateFileA`、`FindFirstFileA`等函数，这些函数接受的是多字节字符串（`char*`），而不是宽字符字符串（`wchar_t*`）。这些API在处理文件路径时，会根据当前系统的本地代码页来解释传入的多字节字符串，从而正确地处理文件名。

但操作系统内部实际上是使用`UTF‑16`来存储和处理文件名等文本信息的。所以当调用这些 ANSI API 时，系统会先将传入的多字节字符串转换为 UTF‑16，然后再进行后续的处理。

比如说`windows`下的ANSI的API的工作逻辑就是：会把传入的多字节字符串按当前“ANSI 代码页”（CP_ACP，即 `GetACP` 返回的值）用 MultiByteToWideChar 转成 UTF‑16，然后内核以 UTF‑16 处理文件名。而`GetACP`得到的值是根据系统的“区域设置”决定的，所以如果系统区域设置是中文（简体，中国），`GetACP`返回的就是`936`，也就是`GBK`编码。一个`FindFirstFileA`函数调用示例：
```cpp
WIN32_FIND_DATAA findFileData;
HANDLE hFind = FindFirstFileA("日志.txt", &findFileData);
if (hFind != INVALID_HANDLE_VALUE) {
    // 处理文件
    FindClose(hFind);
}
```
首先，文件系统中本身就存在一个名为“日志.txt”的文件，这个文件名在文件系统中是以 UTF‑16 编码存储的。当调用`FindFirstFileA`函数时，传入的字符串"日志.txt"是一个多字节字符串（`char*`）。系统会根据当前的 ANSI 代码页（假设是 GBK）将这个多字节字符串转换为对应的 UTF‑16 字符串，然后在文件系统中查找与之匹配的文件名。

* **上面例子中的"日志"和源文件的编码格式有关吗？**
可以说有关也可以说无关。因为`FindFirstFileA`函数接受的是多字节字符串，不在乎具体的编码方式，只是传入的字符串"日志.txt"实际上是以当前源文件的编码格式存储的（假设源文件是以 GBK 编码保存的，就是GBK中"日志.txt"对应的一组字节）。然后进入到`FindFirstFileA`内部的时候，Windows 会按当前 ANSI code page （比如GBK编码）将它们解码（转变）为 UTF‑16。因此，如果源文件编码的时候是用UTF-8打开并识别，这个时候输入`日志.txt`是按照UTF-8存储的，其对应的字节序列是假设是`0xAA 0xBB`，但是这个字符序列会按照ANSI代码页（按照GBK转码）处理，这个时候就会出错了。

因此如果使用的是ANSI的API，那么源文件的编码格式就必须和当前系统的ANSI代码页一致，否则就会出现乱码问题。

#### 3.2 UTF 系列

- **Unicode 的三种主要存储方式**
以`Unicode`为例，它提供了三种主要的编码方式：

1. **UTF - 32**：采用定长编码方式，每个字符固定使用一个`uint32_t`（即 4 字节）来存储。这种方式简单直接，字符的存储和访问都很方便，每个字符占用的空间相同。但如果处理大量文本，尤其是包含许多常用英文字符的文本时，会浪费较多空间，因为英文字符实际上不需要这么大的存储空间。
2. **UTF - 16**：一个字符通常使用 1 - 2 个`uint16_t`（即 2 - 4 字节）来存储。对于基本多文种平面（BMP）内的字符，大多可以用 1 个`uint16_t`表示；而对于一些不常用的字符，可能需要 2 个`uint16_t`。这种方式在一定程度上兼顾了空间和表示能力，对于许多常见的字符，包括英文字符和部分亚洲语言字符，都能较为高效地存储。例如，一个英文字符用一个`uint16_t`存储，中文、日文等字符在 BMP 内的也用一个`uint16_t`。
3. **UTF - 8**：这是一种广泛使用的变长编码方式，一个字符用 1 - 4 个`uint8_t`（即 1 - 4 字节）存储。它根据字符的使用频率来分配存储空间，常用字符（如英文字符、数字等）用较少的字节存储，而不常用的字符（如一些罕见的符号、生僻字等）则用较多字节。一般情况下，一个英文字符用一个`uint8_t`存储，而中文、日文等字符通常需要三个`uint8_t`。这种方式在存储空间利用上较为高效，尤其适合处理多种语言混合的文本。

##### 3.2.1 UTF - 8

UTF - 8 是一种可变长度的字符编码，它在现代计算机系统和网络应用中被广泛使用，具有以下特点：

- **多字节表示**：在 UTF - 8 编码体系下，一个字符可能由 1 到 4 个字节组成。对于多字节表示的字符（即由 2、3 或 4 个字节构成的字符），除了第一个字节外，其余字节的开头两位固定为`10`。这一特性是 UTF - 8 编码用于区分多字节字符中首字节与后续字节的关键标志。例如，当遇到一个字节以`10`开头时，就知道它是某个多字节字符中的后续字节。
- **字符长度判断**：通过观察第一个字节的最高位模式，可以确定该字符的字节长度。如果第一个字节的二进制表示以`110`开头（即`110xxxxx`形式），那么这个字符是两个字节长；若以`1110`开头（`1110xxxx`形式），则该字符为三个字节长；要是以`11110`开头（`11110xxx`形式），该字符就是四个字节长。这种设计使得 UTF - 8 在处理不同字符时能够灵活地分配存储空间，同时又能准确地解析字符。
- **兼容性与适用性**：UTF - 8 编码具有出色的兼容性，它完全兼容 ASCII 编码。这意味着所有的 ASCII 字符在 UTF - 8 编码中仍然以单字节形式表示，编码值与 ASCII 编码完全相同。同时，UTF - 8 能够支持整个 Unicode 标准，从而可以表示世界上几乎所有语言的字符。在实际应用中，如果文本内容主要以英文字符为主，UTF - 8 编码大部分情况下每个字符只需一个字节，在存储空间上具有明显的优势，能够有效节省空间。然而，当处理以非英文字符为主的文本时，尤其是像中文、日文等语言，字符通常会以三字节或者四字节的形式表示。这是因为 UTF - 8 为了实现可变长度编码和字符解析的准确性，在每个字节中使用了一些比特位作为状态位，相对减少了用于表示字符本身的数据位。

##### 3.2.2 UTF - 16

UTF - 16 也是一种用于表示 Unicode 字符的编码方式，具有以下特性：

- **双字节与四字节表示**：UTF - 16 编码可以使用两个字节或者四个字节来表示一个字符。具体使用哪种长度取决于字符在 Unicode 字符集中的位置。
- **设计考量**：它在一定程度上是针对 UTF - 8 的一些特点进行设计的。UTF - 8 虽然在英文字符为主的场景下节省空间，但对于中文字符等其他语言字符，通常需要三个或四个字节来表示，并且由于控制位的存在，相对减少了数据位的使用。而 UTF - 16 的设计旨在优化这种情况，对于大部分常用的中文字符以及其他语言的常用字符，都可以用两个字节来表示，只有一些不常用的字符才会使用四个字节。这种编码方式在处理包含多种语言字符的文本时，在存储空间和字符处理效率之间提供了一种不同的平衡。虽然具体的编码规则较为复杂，在此不做深入研究，但总体上它为 Unicode 字符的表示提供了一种与 UTF - 8 不同的选择，适用于不同的应用场景。

##### 3.2.3 UTF - 32

UTF - 32 是一种固定长度的 Unicode 字符编码，其主要特点如下：

- **固定四字节表示**：UTF - 32 统一使用四个字节（32 位）来表示每一个 Unicode 字符。这种固定长度的编码方式使得字符处理变得相对简单直接。
- **字符处理优势**：由于每个字符都占用固定的 4 个字节，在处理字符串时，可以通过简单的索引操作直接访问字符串中的任何字符，无需像处理 UTF - 8 或 UTF - 16 字符串那样进行复杂的字节解析和计算。例如，要访问字符串中的第 n 个字符，只需将字符串的起始地址加上 4 \* n 的偏移量，即可直接定位到该字符的存储位置。这种特性使得 UTF - 32 在需要频繁访问或修改字符串中字符的场景下非常高效，大大简化了字符处理的逻辑。
- **空间与兼容性考量**：UTF - 32 使用的存储空间比 UTF - 8 和 UTF - 16 都要多，因为它为每个字符固定分配了四个字节。所以，当内存空间不是主要限制因素，并且应用程序需要进行大量的字符处理操作时，UTF - 32 可能是一个理想的选择。此外，在一些特定的系统或应用中，为了确保与某些特定的软件或硬件的兼容性，也可能会选择使用 UTF - 32 编码。简单概括，UTF - 32 通过固定长度编码，避免了复杂的字符解析过程，以空间换取了处理的便捷性。

##### 3.1.2 windows下的宽字符开发

示例（推荐做法）：
```cpp
// 把 UTF-8 路径转换为 UTF-16 并调用宽字符 API（推荐）
std::wstring utf8_to_wstring(const std::string& s) {
    int sz = MultiByteToWideChar(CP_UTF8, 0, s.c_str(), -1, nullptr, 0);
    if (sz == 0) return {};
    std::wstring w(sz, L'\0');
    MultiByteToWideChar(CP_UTF8, 0, s.c_str(), -1, &w[0], sz);
    if (!w.empty()) w.resize(sz - 1);
    return w;
}

std::string pathUtf8 = u8"中文路径.txt";
std::wstring pathW = utf8_to_wstring(pathUtf8);
WIN32_FIND_DATAW fd;
HANDLE h = FindFirstFileW(pathW.c_str(), &fd);
```

### 4. 字符串的表示

前面以及提及了字符集，字符编码，特别是在字符编码中提到了UTF - 8/16/32等编码方式中，会用多字节来表示一个字符。那我该如何表示一个字符，表示一个字符串呢？

一个简单的办法是使用`char`类型表示一个字节，使用`char`数组表示一个字符串，比如说：
```cpp
char str[] = "Hello, 世界";
```

但是这样的话，`char`类型只能表示一个字节，而`世界`这两个汉字在UTF - 8编码下是用三个字节表示一个汉字的，所以这个字符串实际上是由多个`char`类型的字节组成的。换句话说，`char`类型只存储了根据文件编码格式存储的字节数据，而没有直接表示字符的含义。

如果使用windows变成的`ANSI`编码的话，那么`char`类型的字符串实际上是按照当前系统的ANSI代码页来解释这些字节，从而得到对应的字符。

如果想更好管理这个字符串，就会使用`std::string`类型，`std::string`是C++标准库中提供的字符串类型，它封装了`char`数组，并提供了丰富的字符串操作功能。使用`std::string`可以更方便地处理字符串，比如拼接、查找、替换等操作。但是`std::string`本质上仍然是基于`char`类型的字节数组，所以它并不关心字符串的编码方式。也就是说，`std::string`可以存储任何编码格式的字符串数据，但它并不负责解释这些字节所代表的字符含义。

如果想要表示宽字符字符串，可以使用`wchar_t`类型，`wchar_t`类型用于表示宽字符，通常用于存储Unicode字符。使用`wchar_t`数组可以表示宽字符字符串，比如说：

```cpp
wchar_t wstr[] = L"Hello, 世界";
```

这个字面量字符串使用了`L`前缀，表示它是一个宽字符字符串，编译器会根据平台将其转换为相应的宽字符编码。同样，使用`std::wstring`类型可以更方便地管理宽字符字符串，`std::wstring`是C++标准库中提供的宽字符字符串类型，它封装了`wchar_t`数组，并提供了丰富的字符串操作功能。而UI框架中一般也是使用宽字符字符串来处理文本显示，因为它们通常需要支持多种语言和字符集。因此比如说qt中，一般使用`QString`类型来表示字符串，`QString`内部就是使用`UTF-16`来存储字符串数据。

#### 4.1 C/C++中的字符类型与字符串类型

C/C++ 中字符类型多样，涉及不同编码和平台差异：

| 类型         | 用途            | 编码方式                             | 典型平台大小 |
| ---------- | ------------- | -------------------------------- | ------ |
| `char`     | ASCII/UTF-8   | 编码不定，由源文件决定                      | 1 字节   |
| `wchar_t`  | 宽字符           | Windows: UTF-16/ Linux: UTF-32 | 2/4 字节 |
| `char16_t` | 明确的 UTF-16 字符 | UTF-16                           | 2 字节   |
| `char32_t` | 明确的 UTF-32 字符 | UTF-32                           | 4 字节   |

> **注意**：

* Windows 下 `wchar_t` 是 UTF-16
* Linux/macOS 下 `wchar_t` 通常是 UTF-32
* `char16_t` 和 `char32_t` 是 C++11 引入的，语义明确，推荐用于跨平台 Unicode 字符表示

1. **`char`（常规字符）**
  - **类型大小**：1 字节（8 位）。
  - **常见编码**：ASCII、扩展 ASCII 以及在现代代码中广泛应用的 UTF - 8。
  - **用途**：主要用于处理英文字符、字节流，或者作为 UTF - 8 编码字符串的存储类型。
  - **配套字符串类型**：`std::string`。当源代码以 UTF - 8 格式保存时，`char` 类型的字符串通常直接采用 UTF - 8 编码。这在跨平台开发中极为关键，因为 UTF - 8 是目前最为流行的 Unicode 编码方式。

2. **`wchar_t`（宽字符）**
  - **类型大小**：
      - 在 Windows 平台为 2 字节，采用 **UTF - 16** 编码。
      - 在 Linux/Unix 平台为 4 字节，采用 **UTF - 32** 编码。
  - **用途**：用于处理 Unicode 字符（宽字符），尤其适用于非英文字符集。
  - **配套字符串类型**：`std::wstring`。例如：

  ```cpp
  wchar_t hello[] = L"你好";
  ```
  此处的 `L` 前缀表示该字符串字面量为宽字符类型。编译器会依据所在平台，将其转换为相应编码（UTF - 16 或 UTF - 32）的字符数组，且该编码转换在编译时完成，与源文件的编码格式无关。

  需注意，`wchar_t` 的编码方式依赖于平台，不具备可移植性。因此，在跨平台项目中，建议选用语义更明确的字符类型。

3. **`char16_t` 和 `char32_t`（C++11 引入）**

  为解决 `wchar_t` 因平台而异的问题，C++11 引入了两种明确的 Unicode 字符类型：
  - **`char16_t`**：
      - 大小为 2 字节，固定采用 **UTF - 16** 编码。
      - 对应的字符串字面量前缀为 `u"你好"`。
  - **`char32_t`**：
      - 大小为 4 字节，固定采用 **UTF - 32** 编码。
      - 对应的字符串字面量前缀为 `U"你好"`。

  这两种类型提供了清晰的语义以及一致的跨平台行为，适用于编写对 Unicode 处理要求精确的代码。

4. **`std::string`**
  - **底层类型**：`std::basic_string<char>`。
  - **适用编码**：ASCII、扩展 ASCII 和 UTF - 8。
  - **特点**：
      - 每个字符存储占用 1 字节。
      - 操作高效，且与 C 字符串兼容。
      - 在跨平台使用时表现一致，但编码方式需由程序员自行把控。

  它适用于以 **UTF - 8** 编码存储文本的场景，是现代国际化开发中首选的字符串类型。

5. **`std::wstring`**
  - **底层类型**：`std::basic_string<wchar_t>`。
  - **适用编码**：
      - 在 Windows 平台为 UTF - 16。
      - 在 Unix/Linux 平台为 UTF - 32。
  - **特点**：
      - 支持宽字符的 Unicode 编码。
      - 编码会随平台改变，可能引发跨平台行为不一致的问题。
      - 常用于 Windows API 编程，如 `CreateFileW` 函数。 

### 98. 轶事

历史上 Windows 和一些语言选择 16 位宽字符主要是基于早期 Unicode/ISO 10646 的设计（当时常用的是 UCS‑2，码点范围集中在 BMP，即 0x0000..0xFFFF），因此把 wchar_t 定义为 2 字节在当时看起来合乎实际。后来 Unicode 扩展到了 U+10FFFF，超出 16 位表示范围，UTF‑16 通过 surrogate pair（代理项）支持补充平面，从而变为可变长编码。

因此出现的事实是：Windows 的底层接口长期采用 2 字节的 wchar_t/UTF‑16 API（CreateFileW/FindFirstFileW 等），这成为平台事实；而其他系统（多数 Unix/Linux）在设计时把 wchar_t 定为 4 字节，等价于 UTF‑32 的存储语义。Java 的 char 也保持为 16 位（代表 UTF‑16 code unit），为兼容性提供了大量工具函数来处理超出 BMP 的码点。

工程上常见的实践结论是：  
- 不要把 UTF‑16 当作跨平台的“内码”标准；更通用的内部选择是 UTF‑8（节省空间、广泛支持）或按需使用 UTF‑32（便于按码点索引）。  
- 在与 Windows 系统接口交互时，按需把内部编码转换为 UTF‑16 并调用 W 版本 API；这样既兼顾跨平台实现，又能正确处理 Windows 文件名和界面文本。

### 99. quiz

#### 1. char 是有符号的还是无符号的？为什么 char 是在 windows 平台是有符号的？

在主流编程平台上，`char` 的符号属性因编译器和平台而异。

多数平台，包括 Windows 以及大多数类 Unix 系统（如 Linux、macOS），`char` 默认是有符号的（signed），能表示的整数范围是 -128 到 127。然而，在部分平台，像一些嵌入式系统以及特定类 Unix 系统（如基于 ARM、PowerPC 的系统），`char` 默认是无符号的（unsigned），可表示的整数范围为 0 到 255。

这种差异可能引发一些不易察觉的问题。例如，若代码假定 `char` 为有符号类型，而在 `char` 为无符号的平台上运行，就可能出现意外行为。所以，若代码依赖 `char` 的符号属性，最好明确使用 `signed char` 或 `unsigned char`。

在 Windows 平台，`char` 为有符号类型，这主要源于历史原因与兼容性考量。至于为何 `char` 是有符号的，虽确切缘由难以考证，但可做如下推测：
 - **ASCII 编码的满足**：ASCII 编码仅需 0 - 127 的范围，有符号的 `char` 能够满足这一使用需求。
 - **C 语言历史遗留**：`signed char` 可能是 C 语言发展过程中的历史遗留。有符号的设定便于进行字符类型的数值运算，比如，`'b' - 'a'` 表示字符间距离为 1，而 `'a' - 'b'` 则等于 -1 。或许在早期某个版本的 C 语言中依赖这种特性，所以将 `char` 设置为有符号类型。而 Linux 的嵌入式设备受此历史遗留影响相对较小，因此采用 `unsigned char`。 

#### 2. 网络传输数据的时候,为什么 byte 类型都是 unsigned char 的，signed char 可以吗?

在网络传输数据场景下，一般采用 `unsigned char` 来表示字节，主要基于以下几方面原因：
1. **统一性**：`unsigned char` 在任何平台下都固定表示 0 到 255 的整数。这就确保了在不同系统与平台间进行数据传输时，数据的解读方式始终一致。不同平台对数据类型的处理可能存在差异，而 `unsigned char` 的这种统一性能够有效避免因平台不同导致的数据理解偏差。
2. **无符号特性**：网络传输的数据多为二进制形式，并非表示数值，不存在正负之分。使用 `unsigned char` 可规避因符号位引发的混淆。若采用有符号类型，在处理数据时，符号位的存在可能会使数据处理变得复杂，甚至可能导致错误的解读。
3. **兼容性**：众多网络协议以及函数库都默认数据由 `unsigned char` 类型的字节构成。若使用 `signed char`，极有可能引发兼容性问题，导致数据传输与处理无法正常进行。

虽然理论上 `signed char` 也可以用于网络传输,但由于上述原因,实际上几乎所有的网络协议和函数库都使用 `unsigned char` 来表示字节.
