## 字符编码

### 1. concepts

* 计算机如何存储的？
    本质上来说计算机存储的数据是电信号的有无，也就是`01`数据。那么`01`数据实际上就是二进制呗，若干个`01`数据组合起来就是数字了,二进制十六进制十进制都一样表示嘛。所以电信号可以表示数字。那怎么表示文字呢？
    很简单，人为规定呗。比如说我提前声明了下面的数据就是文字数据，即字符。然后规定`61`就是`a`，`62`就是`b`等等。不同的规定就是不同的`字符集`。
    常见的字符集有`ascii`和`unicode`，前者主要支持英文文本，没有中文；后者支持主流所有文本。

* 计算机如何存储文字数据呢？
    字符集相当于只是规定了整数和字符的映射。并没有解决字符如何存储的问题。以`unicode`为例，简单讲解如何存储。在`unicode`中，支持三种存储方式：
    * `UTF-32`：1个字符用 1 个uint32_t存。
    * `UTF-16`：1个字符用 1-2 个uint16_t存。
    * `UTF-8`：1个字符用 1-4 个uint8_t存。
    那为什么要有3种方式存储呢？因为每个字符出现的频率不一样。如果所有字符出现的频率一样，那就都用`UTF-32`存储，每个字符消耗一样的空间，也叫`定长编码`。但是显然，数字文本、英文文本出现频率要高于中文、阿拉伯文等等。那从节省空间的角度出发，可不可以常用字符用少一些的存储空间，不常用的用多一些存储空间。因此这种就叫做`不定长编码`。
    一般来说`utf-8`一个英文字符用一个uint8_t，但是中文、日文等等就要三个；
    而`utf-16`就是一个英文字符一个uint16_t，中文、日文也是一个uint16_t。
    就看国际化程度了。

* 字符编码设计需要考虑什么？
  * 误码：有一个bit错了，能不能不破坏其他数据
  * 定义域：定义域越大，也就越浪费空间嘛。
  * 开头结尾标记：在变长编码的时候，怎么判断是几个字节的呢？开头结尾加一个标记符之类的。
  ...
  林林总总，不在细究。
    
### 2. unicode标准
> 简单来说，就是世界上所有主流字符的集合。
Unicode 是一个国际标准，用于为世界上所有的字符、符号和表情符号分配一个唯一的数字。这个数字被称为字符的 Unicode 码点。Unicode 的目标是能够表示所有的写作系统，包括拉丁字母、希腊字母、阿拉伯字母、汉字、象形文字等。
Unicode 标准定义了一系列的字符集，每个字符集包含一组字符和它们对应的码点。例如，基本多语言平面（Basic Multilingual Plane，BMP）是最常用的字符集，它包含了大多数现代语言的字符，以及许多符号和标点符号。
Unicode 标准还定义了一些编码方案，如 UTF-8、UTF-16 和 UTF-32，这些编码方案定义了如何将字符的码点转换为字节序列。这使得 Unicode 字符可以被存储在文件中，或者在网络上进行传输。
总的来说，Unicode 标准是一个全球通用的字符编码系统，它使得我们可以在电脑上使用任何语言进行写作和阅读。

### 3. 编码方案
#### 3.1 ascii
* 控制字符：ASCII 的前 32 个字符（0-31）被定义为控制字符，如换行符（ASCII 10，表示为 \n）、回车符（ASCII 13，表示为 \r）等。这些字符主要用于控制设备，而不是表示可视的字符。
* 可打印字符：ASCII 的后 95 个字符（32-126）被定义为可打印字符，包括英文大小写字母、数字、标点符号和一些特殊字符。
* ASCII 标准本身只定义了 0 到 127 的字符集，这些字符占用 7 位。然而，许多系统和编码标准会使用 8 位（一个字节）来存储字符，这就留下了 128 到 255 的空间可以用于其他字符。
* 这个 128 到 255 的范围通常被用于存储特殊字符，例如各种符号、非英语字母等。具体的字符集取决于使用的编码标准。例如，在 ISO 8859-1（也被称为 Latin-1）编码中，这个范围被用于存储西欧语言中的特殊字符，如 á, ñ, ô 等。
* 然而，需要注意的是，这个 128 到 255 的范围并不是 ASCII 标准的一部分，而是由其他编码标准定义的。在不同的编码标准中，这个范围可能代表不同的字符集。

#### 3.2 utf8
* 在UTF-8编码中，一个字符可能由1到4个字节组成。对于多字节的字符（即2、3、4字节），除了第一个字节外，其余字节的开头都是10。这是UTF-8编码的特性，用于区分多字节字符中的首字节和后续字节。
* 如果第一个字节的最高位是 1，那么你可以通过计算这个字节开头的连续 1 的个数来确定这个字符的字节长度。例如，如果第一个字节是 110xxxxx，那么这个字符就是两个字节长；如果第一个字节是 1110xxxx，那么这个字符就是三个字节长；如果第一个字节是 11110xxx，那么这个字符就是四个字节长。
* 所以UTF-8可以兼容ascii，同时可以支持unicode标准。
* 对于英文字符为大多数的时候，utf8大部分时候都是一个字节的，省空间；因为浪费了比较多的bit去做状态位，而非数据位。在非英文字符为主要内容的时候，经常都是三字节或者四字节的。

#### 3.3 utf16
* 可以用两个字节或者四个字节表示一个字符。
* 具体的编码规则不研究了，应该就是针对utf-8的弱点设计的。即utf8中控制位太多，中文字符等其他语言字符基本都是三四字节。而utf16可以使得中文字符都是两个字节表示，一些不常用的才是四字节。

#### 3.4 utf32
* 统一四个字节表示每一个字符。
* 字符处理：由于 UTF-32 对每个字符使用固定的 4 个字节，所以在处理字符时，可以直接通过索引来访问字符串中的任何字符，而不需要像处理 UTF-8 或 UTF-16 字符串那样进行复杂的计算。这使得 UTF-32 在需要频繁访问或修改字符串中的字符时非常有用。
* 内存空间不是问题：UTF-32 使用的存储空间比 UTF-8 和 UTF-16 多，所以如果内存空间不是问题，而且需要进行大量的字符处理，那么 UTF-32 可能是一个好的选择。
* 兼容性：有些系统或应用可能需要使用 UTF-32 来确保与某些特定的软件或硬件的兼容性。
* 简单来说就是不用解析了。

### 4. std::string和std::wstring

设计一个`std::string`需要考虑什么？
1.请问string应该用什么编码来保存?
a)ANSI+:只能保存256种字符
b)GBK+等本地编码:失去不同locale下的通用性，
c)UTF-8+:索引性能暴跌
d)UTF-32+:巨浪费内存
e)UTF-16+:又没索引性能，在英文字母多的时候又浪费内存

2.请问如果提供一个可以将字符串里的“坤”都替换为“鸡”的替换用方法replace+的时候，这个方法的行为应该是
a)原地修改现有字符串
b)原字符串不变，生成一个替换过的新字符串

3.请问如果提供一个将字符串里的小写字母替换成大写字母的方法，你觉得应该考虑哪些字母?
a)拉丁字母
b)希腊字母
c)西里尔字母
d)德语变音字母:ã/
e)法语变音字母:é/
z)根据当前 locale 对应的语言来决定考虑哪些字母

4.请问如果提供一个将字符串按指定分隔符分解成一个字符串列表的split方法，你觉得应该返回怎样的一个容器结构?
a) vector
b) list
c)deque

如你所见，设计string有巨量细节需要考虑，而且很多问题是没有通用解法的。每个解法都有各自的优缺点。C++的标准库做得确实不够好，但是这一部分原因在于C++有着极长的历史，标准库诞生的时候整个业界都还在摸索。另一方面C++作为一个强调性能也强调抽象能力的语言，并不倾向于在一堆各有优缺点，并且没有哪个有明显优势的候选方案中强行选一个作为标准答案。所以最终的结果是C++的标准库中的string类十分朴素，功能十分有限。因此当你对字符串处理有重度需求的时候，你就需要按你自己的需求去扩展C++的标准的string，或者自创string类型

在编程语言中，字符的数据类型决定了可以存储哪些字符以及如何存储这些字符。
在 C 和 C++ 中，有两种主要字符类型
* char
    * 主要用于ASCII
* wchar_t
    * 主要用于Unicode
    * 在Windows平台上,`wchar_t`通常是2字节,使用UTF-16编码.当你在代码中写`wchar_t hello_w[] = L"你好你好你好";`时,`L`前缀告诉编译器这是一个宽字符字符串字面量.编译器会将这个字符串转换为UTF-16编码的宽字符序列,每个宽字符都是一个`wchar_t`.这个转换过程是在编译时完成的,所以它不受运行时环境的影响.
    * 需要注意的是,这个行为是特定于Windows平台的.在其他平台上,`wchar_t`可能是4字节,使用UTF-32编码.在这种情况下,"你"和"好"这两个字符也都会被编码为一个4字节的`wchar_t`.
    * 在Windows平台上,当你在代码中使用`wchar_t`和`L`前缀定义一个宽字符字符串时,编译器会将这个字符串转换为UTF-16编码的宽字符序列.
    
    这个转换过程是在编译时完成的,所以它不受你的输入编码格式的影响.无论你的源代码文件是使用什么编码格式保存的(例如ASCII/UTF-8/GBK等),编译器都会正确地解析这个文件,并将宽字符字符串转换为UTF-16编码.
    需要注意的是,这个行为是特定于Windows平台的.在其他平台上,`wchar_t`可能使用其他的编码方式,例如UTF-32.因此,如果你的代码需要在多个平台上运行,你应该避免依赖于特定的`wchar_t`编码方式.
    在Windows平台上,当你在代码中使用`wchar_t`和`L`前缀定义一个宽字符字符串时,编译器会将这个字符串转换为UTF-16编码的宽字符序列.
    这个转换过程是在编译时完成的,所以它不受你的输入编码格式的影响.无论你的源代码文件是使用什么编码格式保存的(例如ASCII/UTF-8/GBK等),编译器都会正确地解析这个文件,并将宽字符字符串转换为UTF-16编码.
    需要注意的是,这个行为是特定于Windows平台的.在其他平台上,`wchar_t`可能使用其他的编码方式,例如UTF-32.因此,如果你的代码需要在多个平台上运行,你应该避免依赖于特定的`wchar_t`编码方式.

* char16_t
    * c11引入，用于存储utf16
* char32_t
    * c11引入，用于存储utf32

* 总结
`char`和`wchar_t`的主要区别在于它们的长度和编译器对它们的处理方式.
`char`通常用于存储ASCII字符和其他8位编码的字符,如UTF-8.当你在代码中使用`char`定义一个字符串时,编译器通常不会改变字符串的编码.也就是说,如果你的源代码文件是UTF-8编码的,那么`char`字符串也会是UTF-8编码的.
`wchar_t`则是一个宽字符类型,用于存储需要更多位数的字符,如UTF-16或UTF-32字符.当你在代码中使用`wchar_t`和`L`前缀定义一个宽字符字符串时,编译器会将这个字符串转换为特定的宽字符编码.在Windows平台上,这个编码通常是UTF-16.

#### 4.1 std::string和std::wstring有什么不同
`std::string` 和 `std::wstring` 都是 C++ 标准库中的字符串类型,但它们用于处理不同的字符集和编码.

- `std::string` 是用于处理常规字符的字符串类,它通常用于处理 ASCII 和扩展 ASCII 字符.在 `std::string` 中,每个字符通常由一个字节(8位)表示,这取决于 `char` 类型在特定平台上的大小.

- `std::wstring` 是宽字符串类,用于处理宽字符集,如 Unicode.在 `std::wstring` 中,每个字符通常由一个 `wchar_t` 类型的值表示,这个值的大小取决于特定平台上 `wchar_t` 类型的大小.在 Windows 平台上,`wchar_t` 通常是 16 位的,可以用于表示 Unicode 中的基本多语言平面(BMP)中的字符.在一些其他平台上,`wchar_t` 可能是 32 位的,可以用于表示 Unicode 中的所有字符.

选择使用 `std::string` 还是 `std::wstring` 取决于你需要处理的字符数据的类型和编码.如果你只需要处理 ASCII 或扩展 ASCII 字符,那么 `std::string` 可能就足够了.如果你需要处理 Unicode 字符,那么你可能需要使用 `std::wstring`.


### 98. ref
1. https://142857.red/book/unicode/#_4

### 99. quiz 
#### 1. char是有符号的还是无符号的
在主流的编程平台上,`char` 的表现可能会有所不同.具体来说,`char` 是有符号的还是无符号的,取决于编译器和平台.

- **在大多数平台上,包括 Windows 和大多数 Unix-like 系统(如 Linux,macOS)上,`char` 默认是有符号的(signed).** 这意味着它可以表示从 -128 到 127 的整数.

- **然而,在某些平台上,如一些嵌入式系统和某些 Unix-like 系统(如 ARM,PowerPC),`char` 默认是无符号的(unsigned).** 这意味着它可以表示从 0 到 255 的整数.

这种差异可能会导致一些微妙的问题.例如,如果你的代码假设 `char` 是有符号的,然后在一个 `char` 是无符号的平台上运行,那么可能会出现意外的行为.因此,如果你的代码依赖于 `char` 的符号性,那么最好明确地使用 `signed char` 或 `unsigned char`.

#### 2. 为什么char是在windows平台是有符号的?
`char`在Windows平台上是有符号的,这主要是由于历史原因和兼容性考虑.
`char`为什么是有符号的,已经无从考究了.
只能现在推测一下.

* 1. ascii只要求了0-127,所以满足使用要求了.
* 2. signed char可能是C语言历史包袱带下来的,有符号的目的是为了做字符类型的数值运算. 例如,'b'-'a'表示距离为1,而'a'-'b'等于-1.也许在某个古老版本依赖这种性质,因此设置为是有符号的.而linux的嵌入式设备受历史包袱影响较小,所以就是unsigned char了


#### 3. 网络传输数据的时候,为什么byte类型都是unsigned char的,signed char可以吗?
在网络传输数据时,通常使用 `unsigned char` 来表示字节,主要有以下几个原因:

1. **统一性**:`unsigned char` 在所有平台上都表示 0 到 255 的整数,这样可以保证在不同的系统和平台之间传输数据时,数据的解释是一致的.

2. **无符号性**:网络传输的数据通常是二进制数据,而不是数值,所以没有正负之分.使用 `unsigned char` 可以避免由于符号位引起的混淆.

3. **兼容性**:许多网络协议和函数库都假定数据是由 `unsigned char` 类型的字节组成的.如果使用 `signed char`,可能会导致兼容性问题.

虽然理论上 `signed char` 也可以用于网络传输,但由于上述原因,实际上几乎所有的网络协议和函数库都使用 `unsigned char` 来表示字节.

##### 3.1 什么是无符号的兼容性?
这个问题要先关注符号扩展和零扩展.

符号扩展和零扩展是计算机科学中的两种位扩展技术,通常用于将较小的整数类型转换为较大的整数类型.

1. 符号扩展:当我们将一个有符号整数从较小的类型转换为较大的类型时,我们需要保持这个数的符号(正或负).为了做到这一点,我们将较小类型的最高位(也就是符号位)复制到较大类型的所有额外位中.例如,如果我们将一个8位的有符号整数-1(二进制表示为11111111)转换为16位,那么结果将是-1(二进制表示为1111111111111111).

2. 零扩展:当我们将一个无符号整数从较小的类型转换为较大的类型时,我们不需要保持符号,因为无符号整数总是正的.因此,我们可以简单地将较大类型的所有额外位设置为0.例如,如果我们将一个8位的无符号整数255(二进制表示为11111111)转换为16位,那么结果将是255(二进制表示为0000000011111111).

这两种扩展方式都是为了保持数值的正确性.在C++中,这些扩展通常会自动发生,例如当你将一个`char`赋值给一个`int`时.

即使传输的数据是有符号的,但是无符号也不会修改数据,不影响读.

#### 4. byte类型用unsigned char好,还是u8int_t好?
`unsigned char` 和 `uint8_t` 都是无符号的整数类型,但是它们之间存在一些差异:

1. **大小**:`unsigned char` 的大小在不同的平台和编译器上可能会有所不同,但是它至少能够表示 0 到 255 的整数.而 `uint8_t` 是一个精确的 8 位无符号整数类型,它总是能够表示 0 到 255 的整数.

2. **可移植性**:`unsigned char` 是 C++ 标准的一部分,因此它在所有的 C++ 平台和编译器上都是可用的.而 `uint8_t` 是 C99 和 C++11 标准的一部分,因此它在一些较旧的 C++ 平台和编译器上可能不可用.

3. **用途**:`unsigned char` 通常用于表示字符或字节.而 `uint8_t` 通常用于表示精确大小的无符号整数,例如在处理二进制数据或硬件接口时.

总的来说,如果你需要一个精确的 8 位无符号整数,并且你的代码需要在 C++11 或更高版本的平台上运行,那么你应该使用 `uint8_t`.否则,你应该使用 `unsigned char`.
简单来说,unsigned char在c/c++标准其实没有严格限制是8bit的,只是要求是大于等于8bit的.
但是uint8_t又不是c98标准的,因此部分考虑到老代码兼容性的可能会用unsigned char,而新的其实只需要用uint8_t就好了

#### 5. 对于中文来说，utf8是三个字节，utf16是两个字节，为什么说utf8和utf16都支持unicode标准呢？
简单来说unicode为不同字符分配了一个数字 而不管是utf8,utf16,还是utf32经过转换后，都是得到同一个数字。

。Unicode 为世界上的每个字符分配了一个唯一的数字，这个数字被称为“码点”。UTF-8、UTF-16 和 UTF-32 都是 Unicode 的编码方案，它们定义了如何将这些码点转换为字节序列。

UTF-8 使用一到四个字节为每个码点编码，它是一种变长编码方式。UTF-8 的一个重要特性是它与 ASCII 编码兼容，即在 UTF-8 编码中，ASCII 字符的编码与 ASCII 完全相同。

UTF-16 使用两个字节（对于基本多语言平面的字符）或四个字节（对于辅助平面的字符）为每个码点编码。它也是一种变长编码方式，但对于大多数现代使用的字符集（包括所有的 BMP 字符），它使用两个字节编码。

UTF-32 为每个码点使用四个字节编码，它是一种定长编码方式。每个 Unicode 码点直接映射到一个四字节序列，这使得 UTF-32 编码在处理上比 UTF-8 和 UTF-16 简单，但它占用的空间更大。

### 100. 练习
                                                 
```cpp
#include <iostream>
using namespace std;

int main() {
  char hello[] = "你好你好你好";
  std::cout << sizeof(hello) << std::endl; 
  // 如果你好是通过utf8输入，输出19。
  // 如果你好是通过gbk输入的,输出13
  std::cout << hello << std::endl;

  wchar_t hello_w[] = L"你好你好你好";
  std::cout << sizeof(hello_w) << std::endl; 
  // 输出14, 编译器转成了utf16编码。
  // 不管管"你好"输入是以utf8输入，还是其他编码方案输入。

  return 0;
}
```

